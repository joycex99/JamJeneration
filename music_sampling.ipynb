{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAM JENERATION\n",
    "\n",
    "Starter code taken from this blog post on [jazz improvisation](https://www.hackerearth.com/blog/machine-learning/jazz-music-using-deep-learning/) with [Github repo](https://github.com/shubham3121/music-generation-using-rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "music21: Certain music21 functions might need the optional package matplotlib;\n",
      "                  if you run into errors, install it by following the instructions at\n",
      "                  http://mit.edu/music21/doc/installing/installAdditional.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re \n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from glob import glob\n",
    "import IPython\n",
    "import pickle\n",
    "\n",
    "import music21\n",
    "\n",
    "import play # requires pygame installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord, stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs: 26\n",
      "['Beethoven/waldstein_1.mid', 'Beethoven/beethoven_opus90_2.mid', 'Beethoven/waldstein_2.mid', 'Beethoven/beethoven_opus90_1.mid', 'Beethoven/waldstein_3.mid']\n"
     ]
    }
   ],
   "source": [
    "# Any directory with .mid files in here is acceptable. We have 3 in Jazz and 26 in Beethoven.\n",
    "\n",
    "beethoven_songs = glob('Beethoven/*.mid')\n",
    "print(\"Number of songs: {}\".format(len(beethoven_songs)))\n",
    "print(beethoven_songs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs: 18\n"
     ]
    }
   ],
   "source": [
    "mozart_songs = glob('Mozart/*.midi')\n",
    "print(\"Number of songs: {}\".format(len(mozart_songs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Logistic Regression\n",
    "\n",
    "In this super simple baseline, we ignore chords and pretend that all songs are just sequences of individual notes. Given a window of previous notes, we attempt to predict the next one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Notes Simply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_notes(songs):\n",
    "    \"\"\"\n",
    "    Returns a list of notes comprising our music.\n",
    "    For chords in our piece, return the note of our top note.\n",
    "    i.e. [F#5, C#7, C5, etc.]\n",
    "    \"\"\"\n",
    "    notes = []\n",
    "    for file in songs:\n",
    "        # converting .mid file to stream object\n",
    "        midi = converter.parse(file)\n",
    "        notes_to_parse = []\n",
    "        try:\n",
    "            # Given a single stream, partition into a part for each unique instrument\n",
    "            parts = instrument.partitionByInstrument(midi)\n",
    "        except:\n",
    "            pass\n",
    "        if parts: # if parts has instrument parts \n",
    "            notes_to_parse = parts.parts[0].recurse()\n",
    "        else:\n",
    "            notes_to_parse = midi.flat.notes\n",
    "    \n",
    "        for element in notes_to_parse: \n",
    "            if isinstance(element, note.Note):\n",
    "                # if element is a note, extract pitch\n",
    "                notes.append(str(element.pitch))\n",
    "            elif(isinstance(element, chord.Chord)):\n",
    "                # if element is a chord, append the first note\n",
    "                notes.append(str(element.pitches[0]))\n",
    "        print(\"Processed song {}\".format(file))\n",
    "    with open('data/simple_notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "    \n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notes_from_songs(songs):\n",
    "    notes = get_simple_notes(songs)\n",
    "    print(\"Number of notes in dataset: {}\".format(len(notes)))\n",
    "    note_counts = Counter(notes)\n",
    "    print(\"Number of distinct notes in dataset: {}\".format(len(note_counts)))\n",
    "    print(note_counts.most_common(3))\n",
    "    print(\"Guess-most-common classifier accuracy: {}\".format(note_counts.most_common(1)[0][1]/len(notes)))\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed song Beethoven/waldstein_1.mid\n",
      "Processed song Beethoven/beethoven_opus90_2.mid\n",
      "Processed song Beethoven/waldstein_2.mid\n",
      "Processed song Beethoven/beethoven_opus90_1.mid\n",
      "Processed song Beethoven/waldstein_3.mid\n",
      "Processed song Beethoven/beethoven_opus10_2.mid\n",
      "Processed song Beethoven/beethoven_opus10_3.mid\n",
      "Processed song Beethoven/elise.mid\n",
      "Processed song Beethoven/beethoven_opus10_1.mid\n",
      "Processed song Beethoven/beethoven_les_adieux_3.mid\n",
      "Processed song Beethoven/pathetique_1.mid\n",
      "Processed song Beethoven/mond_1.mid\n",
      "Processed song Beethoven/beethoven_les_adieux_2.mid\n",
      "Processed song Beethoven/mond_3.mid\n",
      "Processed song Beethoven/pathetique_2.mid\n",
      "Processed song Beethoven/pathetique_3.mid\n",
      "Processed song Beethoven/mond_2.mid\n",
      "Processed song Beethoven/beethoven_les_adieux_1.mid\n",
      "Processed song Beethoven/beethoven_opus22_1.mid\n",
      "Processed song Beethoven/beethoven_opus22_2.mid\n",
      "Processed song Beethoven/beethoven_hammerklavier_4.mid\n",
      "Processed song Beethoven/beethoven_opus22_3.mid\n",
      "Processed song Beethoven/beethoven_hammerklavier_1.mid\n",
      "Processed song Beethoven/beethoven_opus22_4.mid\n",
      "Processed song Beethoven/beethoven_hammerklavier_3.mid\n",
      "Processed song Beethoven/beethoven_hammerklavier_2.mid\n",
      "Number of notes in dataset: 74603\n",
      "Number of distinct notes in dataset: 78\n",
      "[('C4', 2410), ('G3', 2373), ('E-4', 2266)]\n",
      "Guess-most-common classifier accuracy: 0.03230433092502982\n",
      "Processed song Mozart/mz_332_1.midi\n",
      "Processed song Mozart/mz_311_3.midi\n",
      "Processed song Mozart/mz_330_1.midi\n",
      "Processed song Mozart/mz_311_2.midi\n",
      "Processed song Mozart/mz_570_3.midi\n",
      "Processed song Mozart/mz_333_3.midi\n",
      "Processed song Mozart/mz_331_2.midi\n",
      "Processed song Mozart/mz_331_3.midi\n",
      "Processed song Mozart/mz_333_2.midi\n",
      "Processed song Mozart/mz_570_2.midi\n",
      "Processed song Mozart/mz_570_1.midi\n",
      "Processed song Mozart/mz_331_1.midi\n",
      "Processed song Mozart/mz_330_2.midi\n",
      "Processed song Mozart/mz_311_1.midi\n",
      "Processed song Mozart/mz_545_2.midi\n",
      "Processed song Mozart/mz_545_3.midi\n",
      "Processed song Mozart/mz_330_3.midi\n",
      "Processed song Mozart/sonata_16_c_major.midi\n",
      "Number of notes in dataset: 47745\n",
      "Number of distinct notes in dataset: 60\n",
      "[('D5', 2824), ('E5', 2356), ('C5', 2282)]\n",
      "Guess-most-common classifier accuracy: 0.05914755471777149\n"
     ]
    }
   ],
   "source": [
    "beethoven_notes = notes_from_songs(beethoven_songs)\n",
    "mozart_notes = notes_from_songs(mozart_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Logistic Regression Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(note, note_to_int):\n",
    "    \"\"\" Returns one-hot encoded vector given note, dictionary from notes to indices \"\"\"\n",
    "    n_vocab = len(note_to_int)\n",
    "    one_hot = np.zeros(n_vocab)\n",
    "    note_idx = note_to_int[note]\n",
    "    one_hot[note_idx] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_simple_sequences(notes, sequence_length):\n",
    "    \"\"\"\n",
    "    Prepares vectors of simple notes for one-hot encoding input into LogisticRegression classifer\n",
    "    \n",
    "    returns X, y\n",
    "    X: a list of training examples, where each training example are concatenations of one-hot encodings\n",
    "        Each training input in X is thus (sequence_length * n_vocab) in length\n",
    "    y: a list of notes. Each note corresponds to the next note in corresponding sequence from X\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the unique pitches in the list of notes.\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    n_vocab = len(pitchnames)\n",
    "\n",
    "    # Create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    # Slide a window over our notes, adding sequences to dataset\n",
    "    X, y = [], []\n",
    "    for i in range(0, len(notes) - sequence_length):\n",
    "        sequence_in = notes[i : i + sequence_length]\n",
    "        sequence_in = [one_hot_encoding(n, note_to_int) for n in sequence_in]\n",
    "        sequence_in = np.concatenate(sequence_in, axis=None)\n",
    "        note_out = notes[i + sequence_length]\n",
    "        X.append(sequence_in)\n",
    "        y.append(note_out)\n",
    "    \n",
    "    # TODO: Should we turn our labels into categorical one-hot encodings using np_utils.to_categorical\n",
    "    # TODO: Should we normalize input?\n",
    "    return X, y, note_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_XY(notes):\n",
    "    simple_sequence_length = 10\n",
    "    simple_X, simple_y, note_to_int = prepare_simple_sequences(notes, simple_sequence_length)\n",
    "    print(\"Sequence length: {}\".format(simple_sequence_length))\n",
    "    print(\"Number of distinct notes: {}\".format(len(set(notes))))\n",
    "    print(\"Number of training examples: {}\".format(len(simple_X)))\n",
    "    print(\"First five output notes: {}\".format(simple_y[:5]))\n",
    "    return simple_X, simple_y, note_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length: 10\n",
      "Number of distinct notes: 78\n",
      "Number of training examples: 74593\n",
      "First five output notes: ['G2', 'C3', 'G2', 'C3', 'G2']\n"
     ]
    }
   ],
   "source": [
    "beethoven_X, beethoven_y, beethoven_note_to_int = get_XY(beethoven_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length: 10\n",
      "Number of distinct notes: 60\n",
      "Number of training examples: 47735\n",
      "First five output notes: ['C4', 'E-4', 'C4', 'A4', 'E-4']\n"
     ]
    }
   ],
   "source": [
    "mozart_X, mozart_y, mozart_note_to_int = get_XY(mozart_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the following train-test split procedure could be somewhat flawed. We don't split on unseen (unheard) songs, so a melody that appears multiple times in one song could be picked up later on in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(simple_X, simple_y, test_size=0.15):\n",
    "    simple_X_train, simple_X_test, simple_y_train, simple_y_test = train_test_split(simple_X, simple_y, test_size=test_size)\n",
    "    simple_y_train[:5]\n",
    "    print(\"Train set size: {}\".format(len(simple_y_train)))\n",
    "    print(\"Test set size: {}\".format(len(simple_y_test)))\n",
    "    return simple_X_train, simple_X_test, simple_y_train, simple_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 63404\n",
      "Test set size: 11189\n"
     ]
    }
   ],
   "source": [
    "beethoven = get_train_test(beethoven_X, beethoven_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 40574\n",
      "Test set size: 7161\n"
     ]
    }
   ],
   "source": [
    "mozart = get_train_test(mozart_X, mozart_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length: 10\n",
      "Number of distinct notes: 78\n",
      "Number of training examples: 122338\n",
      "First five output notes: ['G2', 'C3', 'G2', 'C3', 'G2']\n"
     ]
    }
   ],
   "source": [
    "combined_X, combined_y, combined_note_to_int = get_XY(beethoven_notes + mozart_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 103987\n",
      "Test set size: 18351\n"
     ]
    }
   ],
   "source": [
    "combined = get_train_test(combined_X, combined_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Simple Logistic Regression/SVM Multi-Class Classification Model\n",
    "\n",
    "In this simpler problem, we assume that each sequence of notes has one and only one note succeeding it. This makes it a multi-class classification problem.\n",
    "\n",
    "Later we'll have to expand it to multi-label problem for chords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset should be tuple/list of X_train, X_test, y_train, y_test\n",
    "def run_logreg(dataset, c=1.0):\n",
    "    X_train, X_test, y_train, y_test = dataset\n",
    "    logreg = LogisticRegression(C=c, penalty='l2')\n",
    "    logreg.fit(X_train, y_train)\n",
    "    lr_preds_test = logreg.predict(X_test)\n",
    "    print(sklearn.metrics.accuracy_score(lr_preds_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/etang/dev/jam-jeneration/venv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/etang/dev/jam-jeneration/venv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28608454732326394\n"
     ]
    }
   ],
   "source": [
    "run_logreg(beethoven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2987012987012987\n"
     ]
    }
   ],
   "source": [
    "run_logreg(mozart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2609667048117269\n"
     ]
    }
   ],
   "source": [
    "run_logreg(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run_logreg(beethoven, 0.3)\n",
    "# run_logreg(beethoven, 10)\n",
    "# run_logreg(beethoven, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26853791369920404\n",
      "0.28515570451054323\n",
      "0.2964669738863287\n",
      "0.2992598799050412\n"
     ]
    }
   ],
   "source": [
    "run_logreg(mozart, 0.1)\n",
    "run_logreg(mozart, 0.3)\n",
    "run_logreg(mozart, 10)\n",
    "run_logreg(mozart, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28608454732326394"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_preds_test = logreg.predict(simple_X_test)\n",
    "sklearn.metrics.accuracy_score(lr_preds_test, simple_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg2 = LogisticRegression()\n",
    "logreg2.fit(simple_X_train, simple_y_train)\n",
    "lr2_preds_test = logreg.predict(simple_X_test)\n",
    "sklearn.metrics.accuracy_score(lr2_preds_test, simple_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg3 = LogisticRegression()\n",
    "logreg2.fit(simple_X_train, simple_y_train)\n",
    "lr2_preds_test = logreg.predict(simple_X_test)\n",
    "sklearn.metrics.accuracy_score(lr2_preds_test, simple_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(simple_X_train, simple_y_train)\n",
    "svm_preds = svm.predict(simple_y_test)\n",
    "sklearn.metrics.accuracy_score(svm_preds, simple_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [0.3, 1, 10, 50]} # , 'penalty': ['l1', 'l2']\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(LogisticRegression(), param_grid, verbose=1)\n",
    "gs.fit(simple_X_train, simple_y_train)\n",
    "\n",
    "print(\"Best parameters set found on train set:\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "print(\"Grid scores on train set:\")\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composing!\n",
    "\n",
    "In which we attempt to use our previous work to generate a melody and play it.\n",
    "\n",
    "Work in progress. We display and show notes, but haven't yet done the heavy lifting of actually composing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stream_for_note_list(note_list):\n",
    "    \"\"\"\n",
    "    Returns a music21 stream given a list of notes ['A5', 'C#4', 'E#3']\n",
    "    This should allow us to show and play a \n",
    "    \"\"\"\n",
    "    s = stream.Stream()\n",
    "    for n in note_list:\n",
    "        s.append(note.Note(n))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def play_stream(our_stream, save_path=None):\n",
    "    \"\"\"\n",
    "    Displays notes, plays audio, saves MIDI file for a given music21 stream object\n",
    "    \"\"\"\n",
    "    # We use music21 to read in notes, play.py to play music\n",
    "    # Unfortunately, music21 midi player doesn't work with Jupyter so we use play.py\n",
    "    our_stream.show()\n",
    "    save_path = save_path or 'output/temp_stream.midi'\n",
    "    our_stream.write('midi', save_path)\n",
    "    play.play_midi(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 89,
       "width": 748
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music file output/temp_stream.midi loaded!\n"
     ]
    }
   ],
   "source": [
    "simple_stream = stream_for_note_list(simple_notes[400:420])\n",
    "play_stream(simple_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Models\n",
    "\n",
    "(Work in Progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, LSTM, Dropout, Flatten\n",
    "def create_network(network_in, n_vocab): \n",
    "    \"\"\"Create the model architecture\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(100,1), return_sequences=True)) # network_in.shape[1:]\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#     print(network_in.shape[1:])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original jazz rnn code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Chords and Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs: 18\n"
     ]
    }
   ],
   "source": [
    "mozart_songs = glob('Mozart/*.midi')\n",
    "print(\"Number of songs: {}\".format(len(mozart_songs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(songs):\n",
    "    notes = []\n",
    "    for file in songs:\n",
    "        # converting .mid file to stream object\n",
    "        midi = converter.parse(file)\n",
    "        notes_to_parse = []\n",
    "        try:\n",
    "            # Given a single stream, partition into a part for each unique instrument\n",
    "            parts = instrument.partitionByInstrument(midi)\n",
    "        except:\n",
    "            pass\n",
    "        if parts: # if parts has instrument parts \n",
    "            notes_to_parse = parts.parts[0].recurse()\n",
    "        else:\n",
    "            notes_to_parse = midi.flat.notes\n",
    "    \n",
    "        for element in notes_to_parse: \n",
    "            if isinstance(element, note.Note):\n",
    "                # if element is a note, extract pitch\n",
    "                notes.append(str(element.pitch))\n",
    "            elif(isinstance(element, chord.Chord)):\n",
    "                # if element is a chord, append the normal form of the \n",
    "                # chord (a list of integers) to the list of notes. \n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "    \n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A3', 'F4', 'F3', 'A4', 'D5', 'A3', 'A4', 'F3', 'D5', 'F5']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_notes(mozart_songs)[145:155]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Sequence Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab): \n",
    "    sequence_length = 100\n",
    "\n",
    "    # Extract the unique pitches in the list of notes.\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "    # Create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i: i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "    \n",
    "    n_patterns = len(network_input)\n",
    "    \n",
    "    # reshape the input into a format comatible with LSTM layers \n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    \n",
    "    # one hot encode the output vectors\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, LSTM, Dropout, Flatten\n",
    "def create_network(network_in, n_vocab): \n",
    "    \"\"\"Create the model architecture\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(100,1), return_sequences=True)) # network_in.shape[1:]\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#     print(network_in.shape[1:])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "def train(model, network_input, network_output, epochs): \n",
    "    \"\"\"\n",
    "    Train the neural network\n",
    "    \"\"\"\n",
    "    # Create checkpoint to save the best model weights.\n",
    "    filepath = 'weights.best.mozart.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True)\n",
    "    \n",
    "    model.fit(network_input, network_output, epochs=epochs, batch_size=64, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(songs):\n",
    "    \"\"\"\n",
    "    Get notes\n",
    "    Generates input and output sequences\n",
    "    Creates a model \n",
    "    Trains the model for the given epochs\n",
    "    \"\"\"\n",
    "    \n",
    "    epochs = 30\n",
    "    \n",
    "    notes = get_notes(songs)\n",
    "    print('Notes processed')\n",
    "    \n",
    "    n_vocab = len(set(notes))\n",
    "    print('Vocab generated')\n",
    "    \n",
    "    network_in, network_out = prepare_sequences(notes, n_vocab)\n",
    "    print('Input and Output processed')\n",
    "    \n",
    "    model = create_network(network_in, n_vocab)\n",
    "    print('Model created')\n",
    "#     return model\n",
    "    print('Training in progress')\n",
    "    train(model, network_in, network_out, epochs)\n",
    "    print('Training completed')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mozart_songs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a0ea3df72a59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmozart_songs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mozart_songs' is not defined"
     ]
    }
   ],
   "source": [
    "### Train the model \n",
    "model = train_network(mozart_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composition\n",
    "\n",
    "In which we take a model and actually generate music!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model=None):\n",
    "    \"\"\" Generate a piano midi file \"\"\"\n",
    "    #load the notes used to train the model\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "\n",
    "    # Get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    # Get all pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "    \n",
    "    print('Initiating music generation process.......')\n",
    "    \n",
    "    network_input = get_inputSequences(notes, pitchnames, n_vocab)\n",
    "    \n",
    "#             reshaped_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "#         prediction_input = prediction_input / float(n_vocab)\n",
    "        \n",
    "    if not model:\n",
    "        model = create_network(network_input, n_vocab)\n",
    "        print('Loading Model weights.....')\n",
    "        model.load_weights('weights.best.music3.hdf5')\n",
    "    else:\n",
    "        print('Using given model')\n",
    "    \n",
    "    print('Model Loaded')\n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
    "    create_midi(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputSequences(notes, pitchnames, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    # map between notes and integers and back\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    sequence_length = 100\n",
    "    network_input = []\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "\n",
    "    return network_input, note_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Pick a random integer\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "    \n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "    \n",
    "    print('Generating notes........')\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "        \n",
    "        # Predicted output is the argmax(P(h|D))\n",
    "        index = np.argmax(prediction)\n",
    "        # Mapping the predicted interger back to the corresponding note\n",
    "        result = int_to_note[index]\n",
    "        # Storing the predicted output\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        # Next input to the model\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    print('Notes Generated...')\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    \n",
    "    print('Saving Output file as midi....')\n",
    "\n",
    "    midi_stream.write('midi', fp='models/beethoven_30e_output.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-c31b6c086b8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#### Generate a new jazz music\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#### Generate a new jazz music \n",
    "generate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File models/beethoven_5e_output.midi not found! (Couldn't open 'models/beethoven_5e_output.midi')\n"
     ]
    }
   ],
   "source": [
    "### Play the Jazz music\n",
    "play.play_midi('models/beethoven_5e_output.midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved():\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "    n_vocab = len(set(notes))\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    network_input, note_to_int = get_inputSequences(notes, pitchnames, n_vocab)\n",
    "    print(\"Number of distinct notes: {}\".format(n_vocab))\n",
    "    #print(network_input)\n",
    "    \n",
    "    model = create_network(network_input, 275) #n_vocab = 193\n",
    "    print('Loading Model weights.....')\n",
    "    model.load_weights('weights.best.beethoven.hdf5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct notes: 193\n",
      "Loading Model weights.....\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 100, 128)          66560     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 100, 128)          131584    \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               3277056   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 275)               70675     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 275)               0         \n",
      "=================================================================\n",
      "Total params: 3,545,875\n",
      "Trainable params: 3,545,875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_lstm_model = load_saved()\n",
    "saved_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lstm(model, dataset, note_to_int):\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "    # Get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    # Get all pitch names\n",
    "    n_vocab = len(set(notes))    \n",
    "    network_input, note_to_int = get_inputSequences(notes, pitchnames, n_vocab)\n",
    "    network_input = np.array(network_input)\n",
    "    network_input = network_input.reshape((-1, 100, 1))\n",
    "    print(network_input.shape)\n",
    "    print(\"Initial input: \", network_input[0])\n",
    "    int_to_note = {v : k for k, v in note_to_int.items()}\n",
    "    print(\"Initial input as notes: \", np.vectorize(lambda i: int_to_note[i])(network_input[0]))\n",
    "    preds_test = model.predict(network_input)\n",
    "    print(\"Initial output: \", preds_test[0])\n",
    "    return int_to_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47645, 100, 1)\n",
      "Initial input:  [[182]\n",
      " [181]\n",
      " [138]\n",
      " [158]\n",
      " [138]\n",
      " [139]\n",
      " [158]\n",
      " [138]\n",
      " [159]\n",
      " [181]\n",
      " [158]\n",
      " [168]\n",
      " [158]\n",
      " [139]\n",
      " [168]\n",
      " [158]\n",
      " [144]\n",
      " [181]\n",
      " [143]\n",
      " [163]\n",
      " [143]\n",
      " [192]\n",
      " [163]\n",
      " [143]\n",
      " [183]\n",
      " [181]\n",
      " [174]\n",
      " [190]\n",
      " [174]\n",
      " [143]\n",
      " [190]\n",
      " [143]\n",
      " [190]\n",
      " [183]\n",
      " [ 91]\n",
      " [139]\n",
      " [164]\n",
      " [191]\n",
      " [159]\n",
      " [139]\n",
      " [182]\n",
      " [181]\n",
      " [137]\n",
      " [162]\n",
      " [191]\n",
      " [189]\n",
      " [173]\n",
      " [182]\n",
      " [157]\n",
      " [173]\n",
      " [163]\n",
      " [173]\n",
      " [137]\n",
      " [139]\n",
      " [182]\n",
      " [180]\n",
      " [144]\n",
      " [162]\n",
      " [164]\n",
      " [142]\n",
      " [164]\n",
      " [137]\n",
      " [159]\n",
      " [144]\n",
      " [139]\n",
      " [191]\n",
      " [162]\n",
      " [182]\n",
      " [191]\n",
      " [142]\n",
      " [144]\n",
      " [ 71]\n",
      " [157]\n",
      " [ 91]\n",
      " [180]\n",
      " [160]\n",
      " [125]\n",
      " [145]\n",
      " [105]\n",
      " [140]\n",
      " [ 91]\n",
      " [140]\n",
      " [ 91]\n",
      " [140]\n",
      " [ 91]\n",
      " [192]\n",
      " [104]\n",
      " [183]\n",
      " [ 91]\n",
      " [183]\n",
      " [ 91]\n",
      " [183]\n",
      " [ 91]\n",
      " [ 74]\n",
      " [104]\n",
      " [ 74]\n",
      " [104]\n",
      " [ 74]\n",
      " [104]\n",
      " [ 74]]\n",
      "Initial input as notes:  [['F4']\n",
      " ['F3']\n",
      " ['A3']\n",
      " ['C4']\n",
      " ['A3']\n",
      " ['A4']\n",
      " ['C4']\n",
      " ['A3']\n",
      " ['C5']\n",
      " ['F3']\n",
      " ['C4']\n",
      " ['E-4']\n",
      " ['C4']\n",
      " ['A4']\n",
      " ['E-4']\n",
      " ['C4']\n",
      " ['B-4']\n",
      " ['F3']\n",
      " ['B-3']\n",
      " ['D4']\n",
      " ['B-3']\n",
      " ['G5']\n",
      " ['D4']\n",
      " ['B-3']\n",
      " ['F5']\n",
      " ['F3']\n",
      " ['E5']\n",
      " ['G3']\n",
      " ['E5']\n",
      " ['B-3']\n",
      " ['G3']\n",
      " ['B-3']\n",
      " ['G3']\n",
      " ['F5']\n",
      " ['5.9']\n",
      " ['A4']\n",
      " ['D5']\n",
      " ['G4']\n",
      " ['C5']\n",
      " ['A4']\n",
      " ['F4']\n",
      " ['F3']\n",
      " ['A2']\n",
      " ['D3']\n",
      " ['G4']\n",
      " ['G2']\n",
      " ['E4']\n",
      " ['F4']\n",
      " ['C3']\n",
      " ['E4']\n",
      " ['D4']\n",
      " ['E4']\n",
      " ['A2']\n",
      " ['A4']\n",
      " ['F4']\n",
      " ['F2']\n",
      " ['B-4']\n",
      " ['D3']\n",
      " ['D5']\n",
      " ['B-2']\n",
      " ['D5']\n",
      " ['A2']\n",
      " ['C5']\n",
      " ['B-4']\n",
      " ['A4']\n",
      " ['G4']\n",
      " ['D3']\n",
      " ['F4']\n",
      " ['G4']\n",
      " ['B-2']\n",
      " ['B-4']\n",
      " ['4.10']\n",
      " ['C3']\n",
      " ['5.9']\n",
      " ['F2']\n",
      " ['C6']\n",
      " ['9.0']\n",
      " ['B-5']\n",
      " ['7.10']\n",
      " ['A5']\n",
      " ['5.9']\n",
      " ['A5']\n",
      " ['5.9']\n",
      " ['A5']\n",
      " ['5.9']\n",
      " ['G5']\n",
      " ['7.0']\n",
      " ['F5']\n",
      " ['5.9']\n",
      " ['F5']\n",
      " ['5.9']\n",
      " ['F5']\n",
      " ['5.9']\n",
      " ['4.7']\n",
      " ['7.0']\n",
      " ['4.7']\n",
      " ['7.0']\n",
      " ['4.7']\n",
      " ['7.0']\n",
      " ['4.7']]\n",
      "Initial output:  [0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 2.854326e-30\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00]\n"
     ]
    }
   ],
   "source": [
    "int_to_note = test_lstm(saved_lstm_model, beethoven, beethoven_note_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Extract Notes' Vector Embeddings\n",
    "\n",
    "Motivation comes from this paper ( http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/ ) on extracting word vector embeddings from a neural network trained to predict proximate words. In this model, to find the embedding for note, say, 'A5', we feed in a sequence entirely composed of 'A5', then extract the resulting activations of the penultimate layer (a 256 x 1 layer). The logic is that similar notes (for some definition of similar) will share similar latent features that get picked up in this penultimate layer.\n",
    "\n",
    "For documentation, see https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "# Construct a new model which outputs the output from penultimate layer.\n",
    "penultimate_layer_model = Model(inputs=saved_lstm_model.input, outputs=saved_lstm_model.get_layer('dense_11').output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penultimate_layers_notes(layer_model, int_to_note):\n",
    "    note_indices = np.array([i for i,_ in int_to_note.items()])\n",
    "    note_names = np.array([int_to_note[i] for i in note_indices])\n",
    "    print(note_indices)\n",
    "    print(note_names)\n",
    "    network_in = []\n",
    "    input_shape = (100, 1)\n",
    "    for i in note_indices:\n",
    "        print(i * np.ones(input_shape))\n",
    "        network_in.append(i * np.ones(input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '0.1' '0.2' '0.2.6' '0.2.7' '0.3' '0.3.5' '0.3.6' '0.3.6.9' '0.3.7'\n",
      " '0.4' '0.4.6' '0.4.7' '0.5' '0.6' '1' '1.2' '1.3' '1.4' '1.4.7'\n",
      " '1.4.7.10' '1.4.7.9' '1.5' '1.5.8' '1.6' '1.7' '10' '10.0' '10.0.3'\n",
      " '10.0.4' '10.1' '10.1.4' '10.2' '10.2.3' '10.2.5' '10.3' '11' '11.0'\n",
      " '11.1' '11.2' '11.2.4' '11.2.5' '11.2.5.7' '11.2.6' '11.3' '11.3.6'\n",
      " '11.4' '2' '2.3' '2.4' '2.4.8' '2.4.9' '2.5' '2.5.7' '2.5.8' '2.5.8.11'\n",
      " '2.5.9' '2.6' '2.6.9' '2.7' '2.8' '3' '3.5' '3.5.9' '3.6' '3.6.9' '3.7'\n",
      " '3.7.10' '3.8' '3.9' '4' '4.10' '4.5' '4.6' '4.7' '4.7.10' '4.7.11'\n",
      " '4.7.9' '4.8' '4.8.11' '4.9' '5' '5.10' '5.11' '5.7' '5.7.10' '5.7.11'\n",
      " '5.8' '5.8.0' '5.8.10' '5.8.11' '5.9' '5.9.0' '6' '6.10.1' '6.11' '6.7'\n",
      " '6.8' '6.8.0' '6.9' '6.9.0' '6.9.0.2' '6.9.11' '7' '7.0' '7.10' '7.10.0'\n",
      " '7.10.1' '7.10.1.3' '7.10.2' '7.11' '7.11.2' '7.8' '7.9' '7.9.1' '8'\n",
      " '8.0' '8.1' '8.10' '8.10.2' '8.11' '8.11.2' '8.11.2.4' '8.9' '9' '9.0'\n",
      " '9.0.2' '9.0.3' '9.0.3.5' '9.0.4' '9.1' '9.1.4' '9.10' '9.11' '9.11.3'\n",
      " '9.2' 'A1' 'A2' 'A3' 'A4' 'A5' 'B-1' 'B-2' 'B-3' 'B-4' 'B-5' 'B1' 'B2'\n",
      " 'B3' 'B4' 'B5' 'C#2' 'C#3' 'C#4' 'C#5' 'C#6' 'C2' 'C3' 'C4' 'C5' 'C6'\n",
      " 'D2' 'D3' 'D4' 'D5' 'D6' 'E-2' 'E-3' 'E-4' 'E-5' 'E-6' 'E2' 'E3' 'E4'\n",
      " 'E5' 'E6' 'F#2' 'F#3' 'F#4' 'F#5' 'F2' 'F3' 'F4' 'F5' 'F6' 'G#2' 'G#3'\n",
      " 'G#4' 'G#5' 'G2' 'G3' 'G4' 'G5']\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'multiply' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-a74c83095559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpenultimate_layers_notes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenultimate_layer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_to_note\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-118-af1fd2383909>\u001b[0m in \u001b[0;36mpenultimate_layers_notes\u001b[0;34m(layer_model, int_to_note)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnote_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mnetwork_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'multiply' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')"
     ]
    }
   ],
   "source": [
    "penultimate_layers_notes(penultimate_layer_model, int_to_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
